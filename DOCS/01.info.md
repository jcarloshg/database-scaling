# Horizontal Database Scaling - Summary & Strategies

## Quick Summary

**Horizontal scaling (scale-out)** means adding more database servers to distribute the load, rather than upgrading a single server. Data is partitioned across multiple machines, allowing the system to handle more traffic and store more data by adding nodes.

## Most Used Horizontal Scaling Strategies

### 1. **Sharding (Partitioning)** ⭐ Most Popular

**What:** Split data across multiple database instances based on a shard key

**How it works:**

```
Users with ID 1-1000    → Database Shard 1
Users with ID 1001-2000 → Database Shard 2
Users with ID 2001-3000 → Database Shard 3
```

**Sharding Methods:**

#### **A. Range-Based Sharding**

```
Shard 1: users WHERE id BETWEEN 1 AND 1000000
Shard 2: users WHERE id BETWEEN 1000001 AND 2000000
Shard 3: users WHERE id BETWEEN 2000001 AND 3000000
```

✅ Simple to implement  
❌ Can cause hot spots (uneven distribution)

#### **B. Hash-Based Sharding**

```javascript
shard_id = hash(user_id) % number_of_shards;
// User 12345 → hash(12345) % 4 = Shard 2
```

✅ Even distribution  
❌ Difficult to add/remove shards (resharding needed)

#### **C. Geographic Sharding**

```
Shard US-East:  Users in USA East Coast
Shard US-West:  Users in USA West Coast
Shard EU:       Users in Europe
Shard Asia:     Users in Asia
```

✅ Low latency (data close to users)  
✅ Regulatory compliance (GDPR)  
❌ Uneven load if user distribution varies

#### **D. Directory-Based Sharding**

```
Lookup table:
user_id → shard_id
12345   → shard_2
67890   → shard_1
```

✅ Flexible, easy to rebalance  
❌ Lookup table is a single point of failure

**When to use:** Large datasets (TB+), high write loads, need to scale beyond single server

### 2. **Read Replicas (Primary-Replica)**

**What:** One primary database handles writes, multiple replicas handle reads

```
           Primary DB (writes)
                 |
        ┌────────┼────────┐
        ▼        ▼        ▼
    Replica 1  Replica 2  Replica 3
     (reads)    (reads)    (reads)
```

**Types:**

- **Synchronous replication:** Wait for replica confirmation (slower, consistent)
- **Asynchronous replication:** Don't wait (faster, eventual consistency)

**Benefits:**
✅ Scales read operations  
✅ Simple to implement  
✅ Built into most databases

**Limitations:**
❌ Doesn't scale writes  
❌ Replication lag (eventual consistency)  
❌ Primary is still a bottleneck

**When to use:** Read-heavy workloads (90%+ reads), analytics, reporting

### 3. **Database Clustering**

**What:** Multiple database nodes work together as a single system

**Types:**

#### **A. Active-Active Cluster**

```
All nodes accept reads and writes
Node 1 ←→ Node 2 ←→ Node 3
```

✅ High availability  
✅ Load distribution  
❌ Complex conflict resolution

#### **B. Active-Passive Cluster**

```
Primary: Active (reads + writes)
Secondary: Standby (failover only)
```

✅ Simple failover  
❌ Passive nodes underutilized

**Examples:**

- MySQL Cluster (NDB)
- PostgreSQL with Patroni
- Galera Cluster for MySQL/MariaDB
- Oracle RAC

**When to use:** Need high availability + horizontal scaling

### 4. **Multi-Master Replication**

**What:** Multiple nodes can accept writes simultaneously

```
Master 1 ←→ Master 2 ←→ Master 3
(R/W)       (R/W)       (R/W)
```

**Conflict Resolution:**

- Last-write-wins (timestamp-based)
- Application-level resolution
- CRDTs (Conflict-free Replicated Data Types)

**Benefits:**
✅ Scales writes  
✅ No single point of failure  
✅ Geographic distribution

**Challenges:**
❌ Complex conflict handling  
❌ Eventual consistency  
❌ Data integrity concerns

**Examples:**

- MySQL Multi-Master
- PostgreSQL BDR
- CouchDB
- Cassandra

**When to use:** Multi-region deployments, high write loads, need geo-redundancy

### 5. **Partitioning (Vertical vs Horizontal)**

#### **Horizontal Partitioning (Row-based)**

```
Table split by rows:
Partition 1: Users 1-1M
Partition 2: Users 1M-2M
Partition 3: Users 2M-3M
```

#### **Vertical Partitioning (Column-based)**

```
Split columns across databases:
DB1: user_id, username, email
DB2: user_id, profile_data, settings
DB3: user_id, large_binary_data
```

**When to use:**

- Horizontal: Large number of rows
- Vertical: Wide tables with different access patterns

### 6. **NoSQL Databases (Built for Horizontal Scaling)**

**What:** Databases designed from the ground up to scale horizontally

**Key-Value Stores:**

- **Redis Cluster:** Automatic sharding, 16,384 hash slots
- **DynamoDB:** Automatic partitioning by partition key
- **Riak:** Consistent hashing, eventual consistency

**Document Stores:**

- **MongoDB:** Sharded clusters with config servers
- **Couchbase:** Auto-sharding with rebalancing

**Column-Family Stores:**

- **Cassandra:** Ring architecture, tunable consistency
- **HBase:** Region servers, based on Hadoop

**Wide-Column Stores:**

- **BigTable:** Google's distributed storage
- **ScyllaDB:** C++ rewrite of Cassandra

**Benefits:**
✅ Built-in sharding  
✅ Automatic rebalancing  
✅ Horizontal scaling by design  
✅ High availability

**Trade-offs:**
❌ Eventual consistency (usually)  
❌ Limited query capabilities  
❌ No ACID transactions (some support it now)

**When to use:** Massive scale, unstructured data, high availability > consistency

### 7. **Federation (Functional Partitioning)**

**What:** Split database by function/feature rather than by data

```
User Service     → Users DB
Product Service  → Products DB
Order Service    → Orders DB
Payment Service  → Payments DB
```

**Benefits:**
✅ Clear service boundaries  
✅ Independent scaling  
✅ Enables microservices  
✅ Reduced join complexity

**Challenges:**
❌ Cross-database joins difficult  
❌ Distributed transactions  
❌ Data duplication needed

**When to use:** Microservices architecture, different services have different load patterns

### 8. **Connection Pooling & Proxy**

**What:** Distribute database connections across multiple servers

**Tools:**

- **ProxySQL** (MySQL/MariaDB)
- **PgBouncer** (PostgreSQL)
- **HAProxy** (General purpose)
- **Vitess** (MySQL sharding middleware)
- **Citus** (PostgreSQL distributed extension)

**Benefits:**
✅ Connection management  
✅ Query routing  
✅ Load balancing  
✅ Automatic failover

**Architecture:**

```
Applications
     ↓
  Proxy/Router
     ↓
  ┌──┼──┐
  ▼  ▼  ▼
 DB1 DB2 DB3
```

**When to use:** Managing multiple database instances, need intelligent routing

### 9. **CQRS (Command Query Responsibility Segregation)**

**What:** Separate databases for reads and writes

```
Write Side:          Read Side:
Commands → Write DB  Queries → Read DB(s)
              ↓            ↑
           Events ─────────┘
```

**Benefits:**
✅ Optimize each side independently  
✅ Scale reads and writes separately  
✅ Read models can be denormalized  
✅ Multiple read models for different use cases

**Implementation:**

- Write DB: Optimized for transactions (PostgreSQL)
- Read DB: Optimized for queries (Elasticsearch, MongoDB)
- Sync via events or CDC

**When to use:** Complex read requirements, very different read/write patterns

### 10. **Time-Series Partitioning**

**What:** Partition data by time periods

```
orders_2024_01 (January 2024 data)
orders_2024_02 (February 2024 data)
orders_2024_03 (March 2024 data)
```

**Benefits:**
✅ Old data can be archived/deleted easily  
✅ Recent data queries are fast  
✅ Natural partitioning for time-based queries

**Strategies:**

- Table per time period
- Partition by month/week/day
- Archive old partitions to cold storage

**Databases:**

- PostgreSQL: Native partitioning
- TimescaleDB: Hypertables
- InfluxDB: Time-series optimized
- Cassandra: Time-series patterns

**When to use:** Time-series data, IoT, logs, metrics, analytics

## Comparison Matrix

| Strategy          | Scales Reads | Scales Writes | Complexity | Consistency | Best For        |
| ----------------- | ------------ | ------------- | ---------- | ----------- | --------------- |
| **Sharding**      | ✅ Yes       | ✅ Yes        | High       | Eventual    | Massive scale   |
| **Read Replicas** | ✅ Yes       | ❌ No         | Low        | Eventual    | Read-heavy      |
| **Clustering**    | ✅ Yes       | ✅ Yes        | Medium     | Tunable     | HA + Scale      |
| **Multi-Master**  | ✅ Yes       | ✅ Yes        | High       | Eventual    | Multi-region    |
| **NoSQL**         | ✅ Yes       | ✅ Yes        | Medium     | Eventual    | Flexible schema |
| **Federation**    | ✅ Yes       | ✅ Yes        | Medium     | Strong      | Microservices   |
| **CQRS**          | ✅ Yes       | ✅ Yes        | High       | Eventual    | Complex reads   |

## Key Considerations When Choosing

### **1. Data Access Patterns**

- Read-heavy? → Read replicas
- Write-heavy? → Sharding or multi-master
- Mixed? → Combination approach

### **2. Consistency Requirements**

- Strong consistency needed? → Limited horizontal scaling options
- Eventual consistency OK? → More options (NoSQL, async replication)

### **3. Query Patterns**

- Need joins across shards? → Avoid heavy sharding
- Single-key lookups? → Perfect for sharding
- Complex analytics? → Consider CQRS

### **4. Operational Complexity**

- Small team? → Start with read replicas
- Large team? → Can handle sharding/clustering
- Need simplicity? → Managed services (DynamoDB, Aurora)

### **5. Cost**

- Budget constrained? → Vertical scaling might be cheaper initially
- Long-term scale? → Horizontal scaling is more cost-effective

## Implementation Steps

1. **Start Simple**

   - Single database with indexing
   - Connection pooling
   - Query optimization

2. **Add Read Replicas**

   - When reads become bottleneck
   - Easiest horizontal scaling step

3. **Implement Caching**

   - Redis/Memcached
   - Reduce database load

4. **Consider Sharding**

   - When single database can't handle load
   - Plan shard key carefully

5. **Evaluate NoSQL**

   - If relational model is limiting
   - For specific use cases

6. **Optimize Continuously**
   - Monitor metrics
   - Identify bottlenecks
   - Scale specific components

## Common Pitfalls to Avoid

❌ **Premature sharding** - Start simple, shard when needed  
❌ **Poor shard key choice** - Leads to hot spots  
❌ **Ignoring replication lag** - Can cause data inconsistency  
❌ **Not planning for resharding** - Adding/removing shards is hard  
❌ **Cross-shard queries** - Very expensive, design to avoid  
❌ **No monitoring** - Can't optimize what you don't measure

## Quick Decision Tree

```
Is your database the bottleneck?
├─ No → Optimize queries, add indexes
└─ Yes
   ├─ Mostly reads?
   │  └─ Add read replicas
   ├─ Mostly writes?
   │  └─ Consider sharding or NoSQL
   └─ Both?
      └─ Combination: replicas + sharding + caching
```
